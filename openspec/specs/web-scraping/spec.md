# 规格：web-scraping

> **Capability**: 网页抓取
> **Purpose**: 系统必须提供 Agent 抓取指定网页内容的能力，以获取详细信息。

## 需求：抓取网页内容

系统必须提供 Agent 抓取指定网页内容的能力，以获取详细信息。

#### 场景：Agent 抓取网页

- **当** Agent 从搜索结果中获得感兴趣的 URL
- **并且** 调用 `fetch_page_content` 工具并传入 URL
- **那么** 系统必须在 8 秒内返回网页的正文内容
- **并且** 返回内容必须去除 HTML 标签、脚本、样式等无关元素

#### 场景：处理 JavaScript 渲染页面

- **当** 目标网页使用 JavaScript 动态渲染内容
- **那么** 系统必须使用 chromedp 等待页面完全加载
- **并且** 提取渲染后的文本内容
- **并且** 不应返回未渲染的 HTML 源码

#### 场景：无效或不可访问的 URL

- **当** Agent 传入无效的 URL（格式错误、404、超时等）
- **那么** 系统必须返回清晰的错误信息
- **并且** 说明具体失败原因（如 "404 Not Found", "Connection timeout"）

---

## 需求：内容提取和清理

系统必须从网页中提取主要内容，去除导航、广告、脚本等无关信息。

#### 场景：提取正文内容

- **当** 成功加载网页
- **那么** 系统必须提取页面的主要内容区域
- **并且** 移除以下元素：
  - `<script>` 和 `<style>` 标签及其内容
  - `<nav>`、`<header>`、`<footer>` 等导航元素
  - 广告和侧边栏
  - 注释和空白字符

#### 场景：保留结构化信息

- **当** 提取网页内容时
- **那么** 系统必须保留标题、段落、列表等文档结构
- **并且** 使用换行符分隔不同段落
- **以便** Agent 可以理解内容的层次结构

#### 场景：提取页面标题

- **当** 抓取网页内容
- **那么** 系统必须同时提取并返回页面的 `<title>` 标签内容
- **并且** 标题必须与正文内容分开返回

---

## 需求：内容长度限制

系统必须控制返回内容的长度，避免超出 LLM 的 token 限制。

#### 场景：默认长度限制

- **当** Agent 调用 `fetch_page_content` 工具
- **那么** 系统默认返回最多 5000 字符的内容
- **并且** 如果页面内容超过 5000 字符，必须进行截断

#### 场景：通知 Agent 内容被截断

- **当** 页面内容超过长度限制被截断
- **那么** 返回结果必须包含 `has_more: true` 标识
- **并且** 包含 `total_length` 字段说明页面完整长度
- **以便** Agent 判断是否需要获取更多内容

#### 场景：支持自定义长度限制

- **当** Agent 需要更多或更少的内容
- **那么** 系统必须支持通过 `max_length` 参数指定返回长度
- **并且** 参数范围应在 1000 到 20000 字符之间

---

## 需求：内容提取器抽象

内容提取逻辑必须与抓取逻辑解耦，便于针对不同网站优化。

#### 场景：通用提取器接口

- **当** 系统设计内容提取组件
- **那么** 必须定义 `Extractor` 接口
- **并且** 该接口必须包含 `Extract(html string) (title, content string, err error)` 方法

#### 场景：默认使用基础提取器

- **当** 没有针对特定网站的专用提取器
- **那么** 系统必须使用基础提取器
- **并且** 基于通用的 HTML 解析规则提取内容

#### 场景：支持添加专用提取器

- **当** 未来需要为财经网站添加专用提取器
- **那么** 开发者只需实现 `Extractor` 接口
- **并且** 可以根据域名选择不同的提取器
- **并且** 不需要修改抓取逻辑

---

## 需求：浏览器渲染能力

系统必须使用真实的浏览器引擎渲染页面，以支持现代网页技术。

#### 场景：使用 Chrome DevTools Protocol

- **当** 系统需要渲染网页
- **那么** 必须使用 chromedp 库与 Chrome 交互
- **并且** 使用 headless 模式运行
- **并且** 支持拦截和禁用图片加载以提升性能

#### 场景：等待页面加载完成

- **当** 访问使用 JavaScript 渲染的网页
- **那么** 系统必须等待页面达到稳定状态
- **并且** 可以使用 `WaitVisible` 或 `WaitReady` 等 chromedp 方法
- **并且** 设置合理的超时时间（如 5 秒）

#### 场景：处理浏览器崩溃

- **当** Chrome 进程意外崩溃或无响应
- **那么** 系统必须检测到异常
- **并且** 返回错误信息给 Agent
- **并且** 尝试重启浏览器实例以恢复服务

---

## 需求：安全性和资源限制

系统必须限制资源使用，防止恶意或异常网页导致问题。

#### 场景：设置页面加载超时

- **当** 访问响应缓慢或无限加载的网页
- **那么** 系统必须在 5 秒后超时
- **并且** 取消页面加载并返回超时错误

#### 场景：限制内存占用

- **当** 同时抓取多个网页或网页包含大量媒体内容
- **那么** 系统必须控制浏览器内存占用
- **并且** 禁用图片、视频等大文件下载
- **并且** 单个页面占用内存不应超过 100MB

#### 场景：处理恶意网页

- **当** 访问包含恶意脚本或无限重定向的网页
- **那么** 系统必须限制重定向次数（最多 3 次）
- **并且** 禁止执行可能有风险的代码（如文件下载）
- **并且** 使用 headless 模式减少攻击面

---

## 需求：与 web-search 工具协同

`fetch_page_content` 工具必须与 `web_search` 工具良好配合。

#### 场景：从搜索结果获取详情

- **当** Agent 先调用 `web_search` 获取搜索结果
- **并且** 对某个结果感兴趣，调用 `fetch_page_content`
- **那么** 系统必须能够成功抓取搜索结果中的 URL
- **并且** 提供比搜索摘要更详细的内容

#### 场景：批量抓取限制

- **当** Agent 尝试在短时间内抓取多个页面
- **那么** 系统必须限制并发数量（最多 2 个并发请求）
- **并且** 避免触发目标网站的反爬虫机制
- **并且** 在请求之间添加随机延迟（1-2 秒）
